{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dshan4585/AI_Expert_Lecture_Files/blob/main/Lab1_2_1_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USu2ano8Faa7"
   },
   "source": [
    "# PyTorch Classification Example #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUXDU3sqDfON"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQXReL8govNS"
   },
   "source": [
    "# MultiLayer Perceptron (MLP)\n",
    "* [5, 3]의 노드로 이루어져 있는 2 hidden layer MLP with 5 and 3 nodes each (total 4 layers)\n",
    "  * 노드 갯수의 변화: 2(입력) -> 5 -> 3 -> 1(출력)\n",
    "  * 은닉층: 모델의 복잡성, 비선형성 증가 \n",
    "* activation function for hidden layers: tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XRwGmEuFp-0"
   },
   "outputs": [],
   "source": [
    "# Mlp\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 5)\n",
    "        self.layer2 = nn.Linear(5, 3)\n",
    "        self.layer3 = nn.Linear(3, 1)\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.layer3(torch.tanh(self.layer2(torch.tanh(self.layer1(x)))))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CqmxX7MHRqr"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, type_, length, std=0.08):\n",
    "        self.length = length\n",
    "        if type_ == 'and':\n",
    "            self.val_l = [0, 0, 0, 1]\n",
    "        elif type_ == 'or':\n",
    "            self.val_l = [0, 1, 1, 1]\n",
    "        elif type_ == 'xor':\n",
    "            self.val_l = [0, 1, 1, 0]\n",
    "        else:\n",
    "            self.val_l = [0, 0, 0, 0]\n",
    "     \n",
    "        self.dataset = []\n",
    "        for i in range(length):\n",
    "            x = np.random.normal(i % 2, std)\n",
    "            y = np.random.normal((i // 2) % 2, std)\n",
    "            val = self.val_l[i%4]\n",
    "            self.dataset.append((x, y, val))\n",
    "      \n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y, val = self.dataset[idx]\n",
    "        return (torch.Tensor([x, y]), torch.Tensor([val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZgNCHs4IF9L"
   },
   "outputs": [],
   "source": [
    "DATASET = DataGenerator('xor', 1000)\n",
    "lr = 0.1 # learning rate\n",
    "batch_size = 20\n",
    "num_epochs = 10\n",
    "num_workers = 4\n",
    "graph_x = np.linspace(-1.0, 2, 2)\n",
    "\n",
    "params = {\n",
    "    'batch_size' : batch_size,\n",
    "    'shuffle' : True,\n",
    "    'num_workers' : num_workers\n",
    "}\n",
    "\n",
    "dataloader = DataLoader(DATASET, **params)\n",
    "model = Mlp().cuda()\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1crD9BAMIuCz"
   },
   "outputs": [],
   "source": [
    "def show(model):\n",
    "    for item in DATASET.get_dataset():\n",
    "        x, y, val = item\n",
    "        if val == 1:\n",
    "            plt.scatter(x, y, c='red', s=10)\n",
    "        else:\n",
    "            plt.scatter(x, y, c='blue', s=10)\n",
    "    for x in np.arange(-0.2, 1.2, 0.05):\n",
    "        for y in np.arange(-0.2, 1.2, 0.05):\n",
    "            val = model(torch.Tensor([x, y]).cuda())\n",
    "            val = val.data.tolist()[0]\n",
    "            plt.scatter(x, y, c=[[val, 0, 1-val]], s=2)\n",
    "    plt.show()\n",
    "\n",
    "show(model)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, val in dataloader:\n",
    "        x = x.cuda()\n",
    "        val = val.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        val_ =  model(x)\n",
    "        loss = torch.sum(torch.pow(val - val_, 2))\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(\"Loss : {:.5f}\".format(total_loss / len(DATASET)))\n",
    "  \n",
    "    if epoch % 10  == 9:\n",
    "        show(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v64D5-gTgFZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Lab2_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
